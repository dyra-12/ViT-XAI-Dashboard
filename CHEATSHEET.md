# ğŸš€ ViT Auditing Toolkit - Quick Reference

## One-Liner Commands

```bash
# Quick start
python app.py

# Download sample images
python download_samples.py

# Run tests
pytest tests/ -v

# Run with Docker
docker-compose up

# Check code style
black --check src/ tests/ app.py

# Generate coverage report
pytest --cov=src --cov-report=html tests/
```

---

## ğŸ“‚ Project Structure Quick Map

```
ViT-XAI-Dashboard/
â”œâ”€â”€ app.py                          # ğŸ¯ Main application - START HERE
â”œâ”€â”€ requirements.txt                # ğŸ“¦ Dependencies
â”‚
â”œâ”€â”€ src/                            # ğŸ§  Core functionality
â”‚   â”œâ”€â”€ model_loader.py            # Load ViT models from HF
â”‚   â”œâ”€â”€ predictor.py               # Make predictions
â”‚   â”œâ”€â”€ explainer.py               # XAI methods (Attention, GradCAM, SHAP)
â”‚   â”œâ”€â”€ auditor.py                 # Advanced auditing tools
â”‚   â””â”€â”€ utils.py                   # Helper functions
â”‚
â”œâ”€â”€ examples/                       # ğŸ–¼ï¸ Test images (20 images)
â”‚   â”œâ”€â”€ basic_explainability/      # For Tab 1
â”‚   â”œâ”€â”€ counterfactual/           # For Tab 2
â”‚   â”œâ”€â”€ calibration/              # For Tab 3
â”‚   â”œâ”€â”€ bias_detection/           # For Tab 4
â”‚   â””â”€â”€ general/                  # Misc testing
â”‚
â”œâ”€â”€ tests/                         # ğŸ§ª Unit tests
â”‚   â”œâ”€â”€ test_phase1_complete.py   # Basic tests
â”‚   â””â”€â”€ test_advanced_features.py # Advanced tests
â”‚
â””â”€â”€ Documentation/                 # ğŸ“š All docs
    â”œâ”€â”€ README.md                 # Main documentation
    â”œâ”€â”€ QUICKSTART.md            # 5-minute setup
    â”œâ”€â”€ TESTING.md               # Testing guide
    â”œâ”€â”€ CONTRIBUTING.md          # Dev guidelines
    â””â”€â”€ PROJECT_SUMMARY.md       # This file
```

---

## ğŸ¯ Common Tasks

### Start the Dashboard
```bash
python app.py
# Opens at http://localhost:7860
```

### Test a Single Tab
```bash
# 1. Start app: python app.py
# 2. Go to http://localhost:7860
# 3. Load ViT-Base model
# 4. Tab 1: Upload examples/basic_explainability/cat_portrait.jpg
# 5. Click "Analyze Image"
```

### Add New Test Image
```bash
# Option 1: Manual
cp /path/to/image.jpg examples/basic_explainability/

# Option 2: Download from URL
curl -L "https://example.com/image.jpg" -o examples/general/my_image.jpg
```

### Run Quick Test
```bash
# Smoke test (verify everything works)
python app.py &
sleep 10
curl http://localhost:7860
# If no error, you're good!
```

---

## ğŸ” Tab Reference

### Tab 1: Basic Explainability (ğŸ”)
**Purpose**: Understand predictions  
**Methods**: Attention, GradCAM, GradientSHAP  
**Best Images**: examples/basic_explainability/  
**Use When**: Want to see what model focuses on

### Tab 2: Counterfactual Analysis (ğŸ”„)
**Purpose**: Test robustness  
**Methods**: Patch perturbation (blur/blackout/gray/noise)  
**Best Images**: examples/counterfactual/  
**Use When**: Testing prediction stability

### Tab 3: Confidence Calibration (ğŸ“Š)
**Purpose**: Validate confidence scores  
**Methods**: Calibration curves, reliability diagrams  
**Best Images**: examples/calibration/  
**Use When**: Checking if confidence matches accuracy

### Tab 4: Bias Detection (âš–ï¸)
**Purpose**: Find performance disparities  
**Methods**: Subgroup analysis  
**Best Images**: examples/bias_detection/  
**Use When**: Testing fairness across conditions

---

## ğŸ¨ Customization Quick Tips

### Change Port
```python
# app.py, last line:
demo.launch(server_port=7860)  # Change 7860 to your port
```

### Add New Model
```python
# src/model_loader.py:
SUPPORTED_MODELS = {
    "ViT-Base": "google/vit-base-patch16-224",
    "ViT-Large": "google/vit-large-patch16-224",
    "Your-Model": "your-username/your-vit-model",  # Add this
}
```

### Modify Colors
```python
# app.py, custom_css variable:
# Change gradient colors, backgrounds, etc.
```

---

## ğŸ› Troubleshooting Quick Fixes

### Port Already in Use
```bash
# Linux/Mac:
lsof -ti:7860 | xargs kill -9
# Windows:
netstat -ano | findstr :7860
taskkill /PID <PID> /F
```

### Out of Memory
```python
# Use smaller model
model_choice = "ViT-Base"  # instead of ViT-Large

# Or clear GPU cache
import torch
torch.cuda.empty_cache()
```

### Model Download Fails
```bash
# Set cache directory
export HF_HOME="/path/to/writable/dir"
export TRANSFORMERS_CACHE="/path/to/writable/dir"
```

### Slow Inference
```bash
# Check GPU availability
python -c "import torch; print(torch.cuda.is_available())"

# Install CUDA version if False
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

---

## ğŸ“Š Model Comparison

| Feature | ViT-Base | ViT-Large |
|---------|----------|-----------|
| Parameters | 86M | 304M |
| Memory | ~2GB | ~4GB |
| Speed | Faster | Slower |
| Accuracy | ~81% | ~83% |
| Best For | Quick tests | Production |

---

## ğŸ§ª Testing Shortcuts

### Minimal Test (30 seconds)
```bash
python app.py &
# Load model â†’ Upload cat_portrait.jpg â†’ Analyze
```

### Full Test (5 minutes)
```bash
# One image per tab
Tab 1: cat_portrait.jpg
Tab 2: flower.jpg
Tab 3: clear_panda.jpg
Tab 4: dog_daylight.jpg
```

### Comprehensive Test (30 minutes)
```bash
# Follow TESTING.md for all 22 tests
```

---

## ğŸ“š Documentation Quick Links

- **Setup**: QUICKSTART.md
- **Testing**: TESTING.md
- **Contributing**: CONTRIBUTING.md
- **Full Docs**: README.md
- **This Guide**: PROJECT_SUMMARY.md

---

## ğŸ”— Useful URLs

```bash
# Local
http://localhost:7860              # Main app
http://localhost:7860/docs         # API docs (if enabled)

# Hugging Face (after deployment)
https://huggingface.co/spaces/YOUR-USERNAME/vit-auditing-toolkit

# GitHub (your repo)
https://github.com/dyra-12/ViT-XAI-Dashboard
```

---

## âŒ¨ï¸ Keyboard Shortcuts (Browser)

- `Ctrl/Cmd + R`: Reload interface
- `Ctrl/Cmd + Shift + I`: Open dev tools
- `Ctrl/Cmd + K`: Clear console

---

## ğŸ“¦ File Sizes Reference

```
Total Project: ~1.6 MB
â”œâ”€â”€ Code: ~200 KB
â”œâ”€â”€ Images: ~1.3 MB
â”œâ”€â”€ Docs: ~100 KB
â””â”€â”€ Config: ~10 KB
```

---

## ğŸ¯ Performance Benchmarks

**Typical Response Times**:
- Model Loading: 5-15s (first time)
- Prediction: 0.5-2s
- Attention Viz: 1-3s
- GradCAM: 2-4s
- GradientSHAP: 8-15s
- Counterfactual: 10-30s
- Calibration: 5-10s
- Bias Detection: 5-10s

---

## ğŸ’¡ Pro Tips

1. **Use ViT-Base** for quick testing
2. **Use ViT-Large** for production/demos
3. **Cache results** if analyzing same image repeatedly
4. **Start with Tab 1** to understand predictions
5. **Use examples/** images for consistent testing
6. **Check TESTING.md** for detailed test cases
7. **Read CONTRIBUTING.md** before making changes

---

## ğŸ†˜ Getting Help

1. Check this file first
2. Read relevant documentation
3. Search GitHub issues
4. Open new issue with details
5. Join discussions

---

## âœ… Pre-Demo Checklist

Before showing to others:

- [ ] App runs without errors
- [ ] All tabs functional
- [ ] Sample images loaded
- [ ] Model loads quickly
- [ ] UI looks professional
- [ ] No console errors
- [ ] README updated with your info

---

**Keep this file handy for quick reference! ğŸ“Œ**

*Last updated: October 26, 2024*
